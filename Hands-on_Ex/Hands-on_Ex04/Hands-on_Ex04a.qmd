---
title: "Hands-on Exercise 04a - Visual Statistical Analysis"
author: "Ong Chae Hui"
format: 
  html:
    code-fold: true
engine: knitr
---

## 1. Getting Started

### 1.1. Installing and Loading the required R Packages

In this exercise using Exam_data, we will be using **ggstatsplot** and **tidyverse**. **rstantools** and **PMCMRplus** are also be required for plotting the ONEWAY ANOVA graph.

```{r}
pacman::p_load(ggstatsplot, tidyverse, rstantools)
```

### 1.2. Importing Data (Exam_data)

For this exercise, Exam_data.csv provided will be imported into R by using `read_csv()` of **readr** package.

```{r message=FALSE}
exam_data <- read_csv("data/Exam_data.csv")
```

### 1.3. One-sample test: `gghistostats()` method

In the code chunk below, `gghistostats()` is used to to build an visual of one-sample test on English scores, with default information: - statistical details - Bayes Factor - sample sizes - distribution summary.

```{r}
set.seed(1234)

gghistostats(
  data = exam_data,
  x = ENGLISH,
  type = "bayes",
  test.value = 60,
  xlab = "English scores"
)
```

#### 1.3.1. Additional Information on the Bayes Factor

-   A Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.

-   That's because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.

-   When we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as

![](images/01_Bayes_img1.jpg){fig-align="center" width="630"}

-   The [Schwarz criterion](https://www.statisticshowto.com/bayesian-information-criterion/) is one of the easiest ways to calculate rough approximation of the Bayes Factor.

##### 1.3.1.1. Interpreting the Bayes Factor

A **Bayes Factor** can be any positive number. One of the most common interpretations is this one---first proposed by Harold Jeffereys (1961) and slightly modified by [Lee and Wagenmakers](https://www-tandfonline-com.libproxy.smu.edu.sg/doi/pdf/10.1080/00031305.1999.10474443?needAccess=true) in 2013:

![](images/02_Bayes_img2.jpg){fig-align="center" width="616"}

### 1.4. Two-sample mean test: `ggbetweenstats()` method

The code chunk below shows `ggbetweenstats()` being used to build a visual for two-sample mean test of Maths scores by gender.Default information: - statistical details - Bayes Factor - sample sizes - distribution summary

```{r}
ggbetweenstats(
  data = exam_data,
  x = GENDER, 
  y = MATHS,
  type = "np",
  messages = FALSE
)
```

### 1.5. Oneway ANOVA Test: `ggbetweenstats()` method

The code chunk below shows `ggbetweenstats()` being used to build a visual for One-way ANOVA test on English score by race.

-   "ns" → only non-significant
-   "s" → only significant
-   "all" → everything

```{r}
ggbetweenstats(
  data = exam_data,
  x = RACE, 
  y = ENGLISH,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

#### 1.5.1. ggbetweenstats - Summary of tests

![](images/03_ggbetweenstats_SummaryofTests_img1.jpg){fig-align="center" width="622"}

![](images/04_ggbetweenstats_SummaryofTests_img2.jpg){fig-align="center" width="619"}

![](images/05_ggbetweenstats_SummaryofTests_img3.jpg){fig-align="center" width="623"}

### 1.6. Significant Test of Correlation: `ggscatterstats()` method

The code chunk below shows `ggscatterstats()` being used to build a visual for Significant Test of Correlation between Maths scores and English scores.

```{r}
ggscatterstats(
  data = exam_data,
  x = MATHS,
  y = ENGLISH,
  marginal = FALSE,
  )
```

### 1.7. Significant Test of Association (Depedence) : `ggbarstats()` methods

In the code chunk below, the Maths scores is binned into a 4-class variable by using `cut()`.

```{r}
exam1 <- exam_data %>% 
  mutate(MATHS_bins = 
           cut(MATHS, 
               breaks = c(0,60,75,85,100))
)
```

We then use `ggbarstats()` to build a visual for Significant Test of Association, as shown in the code chunk below.

```{r}
ggbarstats(exam1, 
           x = MATHS_bins, 
           y = GENDER)
```

## 2. Visualising Models

In this section, we will visualise model diagnostic and model parameters by using parameters package.

Toyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.

### 2.1. Getting Started - Installing and Loading the required R Packages

```{r}
pacman::p_load(readxl, performance, parameters, see)
```

### 2.2. Importing Data (ToyotaCorolla.xls)

For this exercise, ToyotaCorolla.xls provided will be imported into R by using `read_xls()` of **readxl** package.

```{r message=FALSE}
car_resale <- read_xls("data/ToyotaCorolla.xls", 
                       "data")
car_resale
```

### 2.3. Multiple Regression Model using `lm()`

The code chunk below is used to calibrate a multiple linear regression model by using `lm()` of Base Stats of R.

```{r}
model <- lm(Price ~ Age_08_04 + Mfg_Year + KM + 
              Weight + Guarantee_Period, data = car_resale)
model
```

### 2.4. Model Diagnostic: checking for multicolinearity

Using `check_collinearity()` method from the **performance** package

```{r}
check_collinearity(model)
```

```{r message=FALSE}
check_c <- check_collinearity(model)
plot(check_c)
```

### 2.5. Model Diagnostic: checking normality assumption

Using `check_normality()` method from the **performance** package

```{r}
model1 <- lm(Price ~ Age_08_04 + KM + 
              Weight + Guarantee_Period, data = car_resale)

check_n <- check_normality(model1)

plot(check_n)
```

### 2.6. Model Diagnostic: Check model for homogeneity of variances

Using `check_heteroscedasticity()` method from the **performance** package

```{r}
check_h <- check_heteroscedasticity(model1)

plot(check_h)
```

### 2.7. Model Diagnostic: Complete check

We can also perform the complete by using `check_model()`.

```{r}
check_model(model1)
```

### 2.8. Visualising Regression Parameters: see methods

In the code below, `plot()` of **see** package and `parameters()` of **parameters** package are used to visualise the parameters of a regression model.

```{r}
plot(parameters(model1))
```

### 2.9. Visualising Regression Parameters: `ggcoefstats()` method

This example uses `ggcoefstats()` of **ggstatsplot** package to visualise the parameters of a regression model.

```{r}
ggcoefstats(model1, 
            output = "plot")
```
